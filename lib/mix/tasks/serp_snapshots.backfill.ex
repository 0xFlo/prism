defmodule Mix.Tasks.SerpSnapshots.Backfill do
  @moduledoc """
  Runs the SERP snapshot enrichment backfill so historic rows gain the new
  competitor metadata, content-type classifications, and ScrapFly citation
  flags added in Story 2.

  ## Options

    * `--batch-size N` / `-b N` â€“ rows per batch (default: 100)
    * `--limit N` / `-l N` â€“ maximum rows to process (useful for rehearsals)
    * `--dry-run` / `-d` â€“ report what would change without updating the DB
    * `--resume-after ISO8601` / `-r ISO8601` â€“ skip rows inserted before the timestamp

  ## Examples

      # Standard execution with defaults
      mix serp_snapshots.backfill

      # Quick rehearsal of 250 rows (no writes)
      mix serp_snapshots.backfill --limit 250 --dry-run

      # Resume after a timestamp with smaller batches
      mix serp_snapshots.backfill --resume-after 2025-11-15T00:00:00Z --batch-size 50
  """

  use Mix.Task

  alias GscAnalytics.SerpSnapshots.Backfill

  @shortdoc "Backfills SERP snapshots with enriched competitor metadata"

  @switches [
    batch_size: :integer,
    limit: :integer,
    dry_run: :boolean,
    resume_after: :string
  ]
  @aliases [b: :batch_size, l: :limit, d: :dry_run, r: :resume_after]

  @impl Mix.Task
  def run(args) do
    Mix.Task.run("app.start")

    {opts, _} = OptionParser.parse!(args, strict: @switches, aliases: @aliases)

    backfill_opts =
      opts
      |> Enum.reject(fn {_key, value} -> is_nil(value) end)

    Mix.shell().info("""

    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  SERP Snapshot Backfill                                    â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    â€¢ Batch size:     #{display_opt(opts[:batch_size], 100)}
    â€¢ Limit:          #{display_opt(opts[:limit], "âˆž")}
    â€¢ Dry run:        #{opts[:dry_run] == true}
    â€¢ Resume after:   #{display_opt(opts[:resume_after], "not set")}

    Parsing stored ScrapFly HTML to normalize competitors/content types...
    """)

    case Backfill.run(backfill_opts) do
      {:ok, summary} ->
        print_summary(summary)

      {:error, reason} ->
        Mix.raise("SERP snapshot backfill failed: #{inspect(reason)}")
    end
  end

  defp display_opt(nil, default), do: default
  defp display_opt(value, _default), do: value

  defp print_summary(summary) do
    Mix.shell().info("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  Backfill Complete                                         â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ðŸ” Dry run:             #{summary.dry_run}
    ðŸ“¦ Batch size:          #{summary.batch_size}
    ðŸ“ˆ Processed rows:      #{summary.total}
    âœï¸  Updated rows:       #{summary.updated}
    â­ï¸  Skipped rows:       #{summary.skipped}
    âš ï¸  Recent errors:      #{length(summary.errors)}
    ðŸ•’ Last processed ID:   #{summary.last_processed_id || "n/a"}
    ðŸ•’ Last processed at:   #{summary.last_processed_at || "n/a"}

    #{error_lines(summary.errors)}
    """)
  end

  defp error_lines([]), do: "No errors reported."

  defp error_lines(errors) do
    (["Recent errors:"] ++ Enum.map(errors, &format_error/1))
    |> Enum.join("\n")
  end

  defp format_error(%{id: id, reason: reason}), do: "  â€¢ #{id}: #{reason}"
  defp format_error(other), do: "  â€¢ #{inspect(other)}"
end
